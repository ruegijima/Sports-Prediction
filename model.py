# -*- coding: utf-8 -*-
"""
Created on Sat Mar 11 13:23:13 2023

@author: Hp
"""

"""Sports_Prediction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1iOC9RY-r1oWwy0yC9kuUbOQNOLXBomXI
"""

import numpy as np
import pandas as pd
import sklearn
import joblib
import pickle
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score
from sklearn import tree, metrics
from sklearn.metrics import mean_squared_error
from math import sqrt
from datetime import datetime
players_df = pd.read_csv('players_22.csv')

#Overall info on the dataset
players_df.info()

#columns of the dataset
players_df.columns

#Shape of the dataset
players_df.shape

# check for datatypes, some might require changing depending on what needs to be done.
players_df.dtypes

# View summary statistics
players_df.describe()

# Droping irrelevant columns
players_df.drop(['sofifa_id', 'player_url', 'short_name', 'long_name', 'dob', 'real_face', 'nation_jersey_number', 'nation_position'], axis=1, inplace=True)

# checking for missing values
players_df.isnull().any()

#lets handle the above missing values
col = []
for c in players_df.columns:
    missing_values=np.mean(players_df[c].isnull())* 100
    if missing_values > 60:
        print('{} - {}%'.format(c, round(missing_values)))
        col.append(c)

print("\n We need to drop these columns: \n \n", col)

#Dropping the columns with missing values
players_df.drop(columns=['club_loaned_from', 'nation_team_id', 'player_tags', 'goalkeeping_speed', 'nation_logo_url'], inplace=True)

# Droping rows with missing data
players_df.dropna(inplace=True)

players_df = players_df.loc[:, players_df.notna().all()]

# Extract preferred foot
players_df['preferred_foot'] = players_df['preferred_foot'].apply(lambda x: 1 if x == 'Right' else 0)

# Calculate overall potential
players_df['overall_potential'] = players_df['overall'] + players_df['potential']

# Calculate correlation coefficients
corr_matrix = players_df.corr()
corr_matrix['overall'].sort_values(ascending=False)

#Drop less correlated features
players_df.drop(columns=['goalkeeping_positioning','goalkeeping_reflexes','goalkeeping_diving',
                         'goalkeeping_handling','goalkeeping_kicking',
                         'preferred_foot','nationality_id','league_level','club_jersey_number','club_team_id'])

# Select top features
feature_subset = players_df[['age', 'potential', 'value_eur', 'wage_eur', 'international_reputation', 'overall_potential']]

## creating a new df with only numerical dtypes
new_df = players_df[['potential', 'potential', 'value_eur', 'wage_eur',
            'age',  'height_cm', 'weight_kg',
            'pace',
          'shooting',
          'passing',
          'dribbling',
          'defending',
          'physic',
          'attacking_crossing',
          'attacking_finishing',
          'attacking_heading_accuracy',
          'attacking_short_passing',
          'attacking_volleys',
          'skill_dribbling',
          'skill_curve',
          'skill_fk_accuracy',
          'skill_long_passing',
          'skill_ball_control',
          'movement_acceleration',
          'movement_sprint_speed',
          'movement_agility',
          'movement_reactions',
          'movement_balance',
          'power_shot_power',
          'power_jumping',
          'power_stamina',
          'power_strength',
          'power_long_shots',
          'mentality_aggression',
          'mentality_interceptions',
          'mentality_positioning',
          'mentality_vision',
          'mentality_penalties',
          'mentality_composure',
          'defending_marking_awareness',
          'defending_standing_tackle',
          'defending_sliding_tackle',
          'goalkeeping_diving',
          'goalkeeping_handling',
          'goalkeeping_kicking',
          'goalkeeping_positioning',
          'goalkeeping_reflexes',
            ]].copy()

new_df.dtypes

# changing all the dtypes to float64
new_df = new_df.astype(np.float64)

#dropping all the null values
new_df = new_df.notna()
new_df.isnull().any()

#building the models
labels = players_df['overall']
from sklearn.ensemble import RandomForestRegressor
forest = RandomForestRegressor(random_state=42)
forest.fit(new_df, labels)

#Evaluate the model on the testing set
from sklearn.metrics import mean_squared_error
forestPred = forest.predict(new_df)
forest_mse = mean_squared_error(labels, forestPred)
forest_rmse = np.sqrt(forest_mse)
forest_mse, forest_rmse

# Tune the model by adding the parameters to learn from
forest_new = RandomForestRegressor(random_state=42, max_features=1)
forest_new.fit(new_df, labels)

#checking the perfomance of the above model
newForestPred = forest_new.predict(new_df)
newForest_mse = mean_squared_error(labels, newForestPred)
newForest_rmse = np.sqrt(newForest_mse)
newForest_mse, newForest_rmse

"""## Using Data From Another Season"""

import pandas as pd
import joblib
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score

# Load the new dataset
df_test = pd.read_csv('players_21.csv')

new_data= df_test[['overall', 'potential', 'value_eur', 'wage_eur',
            'age',  'height_cm', 'weight_kg',
            'pace',
          'shooting',
          'passing',
          'dribbling',
          'defending',
          'physic',
          'attacking_crossing',
          'attacking_finishing',
          'attacking_heading_accuracy',
          'attacking_short_passing',
          'attacking_volleys',
          'skill_dribbling',
          'skill_curve',
          'skill_fk_accuracy',
          'skill_long_passing',
          'skill_ball_control',
          'movement_acceleration',
          'movement_sprint_speed',
          'movement_agility',
          'movement_reactions',
          'movement_balance',
          'power_shot_power',
          'power_jumping',
          'power_stamina',
          'power_strength',
          'power_long_shots',
          'mentality_aggression',
          'mentality_interceptions',
          'mentality_positioning',
          'mentality_vision',
          'mentality_penalties',
          'mentality_composure',
          'defending_marking_awareness',
          'defending_standing_tackle',
          'defending_sliding_tackle',
          'goalkeeping_diving',
          'goalkeeping_handling',
          'goalkeeping_kicking',
          'goalkeeping_positioning',
          'goalkeeping_reflexes',
            ]].copy()

new_data.dropna(inplace=True)

# Preprocess the data
X = new_data.drop('overall', axis=1)
y = new_data['overall']

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Train the model
clf = LinearRegression()
clf.fit(X_train, y_train)

prediction_linear=clf.predict(X_test)
prediction_linear

#accuracy of testing prediction
acc = clf.score(X_test, y_test)
print(acc)

#accuracy of training dataset
clf.score(X_train,y_train)

# Saving model to disk
pickle.dump(clf, open('model.pkl','wb'))

# Loading model to compare the results
model = pickle.load(open('model.pkl','rb'))
print(model.predict([[2, 9, 6,2, 9, 6,2, 9, 6,2, 9, 6,2, 9, 6,2, 9, 6,2, 9, 6,2, 9, 6,2, 9, 6,2, 9, 6,2, 9, 6,2, 9, 6,2, 9, 6,2, 9, 6,2, 9, 6,2]]))

